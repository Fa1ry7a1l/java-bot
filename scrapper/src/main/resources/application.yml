app:
  useQueue: true
  database-access-type: jdbc
  scheduler:
    enable: true
    interval: PT10s
    force-check-delay: PT10s
  clients:
    gitHub:
      url: https://api.github.com
    stackOverflow:
      url: https://api.stackexchange.com/2.3
    bot:
      url: http://localhost:8090
  retry:
    max-attempts: 3
    retry-status-codes: 500, 502, 503, 504
    type: exponential
    exponential:
      initial-interval-millis: 1000
      multiplier: 2
      max-interval-millis: 100000
  kafka-info:
    servers: ${DOCKER_HOST_IP:127.0.0.1}:9092,${DOCKER_HOST_IP:127.0.0.1}:9093
    topic:
      name: updates
      partitions: 1
      replicas: 1

management:
  metrics:
    tags:
      application: ${spring.application.name}
  server:
    port: 8081
  endpoints:
    web:
      base-path: /
      exposure:
        include: health,info,prometheus
      path-mapping:
        prometheus: metrics


springdoc:
  swagger-ui:
    path=/swagger-ui

spring:
  application:
    name: scrapper
  datasource:
    url: ${bd_url:jdbc:postgresql://localhost:5432/scrapper }
    username: ${db_login:postgres}
    password: ${db_password:postgres}
  liquibase:
    enabled: false
  cache:
    cache-names:
      - rate-limit-buckets
    caffeine:
      spec: maximumSize=100000,expireAfterAccess=3600s
  kafka:
    consumer:
      auto-offset-reset: earliest

bucket4j:
  enabled: true
  filters:
    - cache-name: rate-limit-buckets
      url: .*
      http-response-body: "{ \"status\": 429, \"error\": \"Too Many Requests\", \"message\": \"You sent too many requests. Wait several minutes\" }"
      rate-limits:
        - cache-key: "@ipCheckerService.getClientIP(#this)"
          bandwidths:
            - capacity: 5
              time: 1
              unit: minutes
              refill-speed: interval



server:
  port: 8080

logging:
  config: classpath:log4j2-plain.xml
